/*
 * Copyright (C) 2025 Dominik Drexler
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program. If not, see <https://www.gnu.org/licenses/>.
 */

#include "tyr/datalog/bottom_up.hpp"

#include "tyr/common/chrono.hpp"               // for StopwatchScope
#include "tyr/common/comparators.hpp"          // for operator!=, opera...
#include "tyr/common/config.hpp"               // for uint_t
#include "tyr/common/formatter.hpp"            // for operator<<
#include "tyr/common/types.hpp"                // for make_view, IndexList
#include "tyr/common/vector.hpp"               // for View
#include "tyr/datalog/assignment_sets.hpp"     // for AssignmentSets
#include "tyr/datalog/execution_contexts.hpp"  // for ProgramExecutionC...
#include "tyr/datalog/fact_sets.hpp"           // for FactSets, Predica...
#include "tyr/datalog/generator.hpp"           // for ground
#include "tyr/datalog/rule_scheduler.hpp"      // for RuleSchedulerStratum
#include "tyr/formalism/datalog/merge.hpp"     // for merge, MergeContext
#include "tyr/formalism/datalog/views.hpp"

#include <cista/containers/hash_storage.h>          // for operator!=
#include <gtl/phmap.hpp>                            // for operator!=
#include <memory>                                   // for __shared_ptr_access
#include <oneapi/tbb/enumerable_thread_specific.h>  // for enumerable_thread...
#include <oneapi/tbb/parallel_for.h>                // for parallel_for
#include <oneapi/tbb/parallel_for_each.h>
#include <utility>  // for pair
#include <vector>   // for vector

namespace tyr::datalog
{

static void solve_bottom_up_for_stratum(datalog::ProgramExecutionContext& program_execution_context, datalog::RuleSchedulerStratum& scheduler)
{
    scheduler.activate_all();

    while (true)
    {
        /**
         * Parallel evaluation.
         */

        const auto active_rules = scheduler.get_active_rules();
        scheduler.on_start_iteration();

        {
            auto stopwatch = StopwatchScope(program_execution_context.statistics.ground_seq_total_time);

            oneapi::tbb::parallel_for_each(
                active_rules.begin(),
                active_rules.end(),
                [&](auto&& rule_index)
                {
                    const auto i = uint_t(rule_index);
                    auto& facts_execution_context = program_execution_context.facts_execution_context;
                    auto& rule_execution_context = program_execution_context.rule_execution_contexts[i];
                    auto& rule_stage_execution_context = program_execution_context.rule_stage_execution_contexts[i];
                    auto& thread_execution_context = program_execution_context.thread_execution_contexts.local();

                    {
                        ///--- Initialization phase
                        auto stopwatch = StopwatchScope(rule_execution_context.statistics.init_total_time);

                        thread_execution_context.clear();
                        rule_execution_context.clear();
                        rule_execution_context.initialize(program_execution_context.facts_execution_context.assignment_sets);
                    }

                    {
                        /// --- Grounding phase
                        auto stopwatch = StopwatchScope(rule_execution_context.statistics.ground_total_time);
                        ++rule_execution_context.statistics.num_executions;

                        ground(facts_execution_context, rule_execution_context, rule_stage_execution_context, thread_execution_context);
                    }
                });
        }

        /**
         * Sequential merge.
         */

        /// --- Sequentially combine results into a temporary staging repository to prevent modying the program's repository

        {
            const auto stopwatch = StopwatchScope(program_execution_context.statistics.merge_seq_total_time);

            auto discovered_new_fact = bool { false };

            auto& fluent_predicate_fact_sets = program_execution_context.facts_execution_context.fact_sets.fluent_sets.predicate;
            auto& fluent_predicate_assignment_sets = program_execution_context.facts_execution_context.assignment_sets.fluent_sets.predicate;

            for (const auto rule_index : active_rules)
            {
                const auto i = uint_t(rule_index);

                const auto& rule_execution_context = program_execution_context.rule_execution_contexts[i];
                auto& rule_stage_execution_context = program_execution_context.rule_stage_execution_contexts[i];

                auto merge_context = formalism::datalog::MergeContext { program_execution_context.datalog_builder,
                                                                        *program_execution_context.repository,
                                                                        rule_stage_execution_context.merge_cache };

                for (const auto ground_head_index : rule_execution_context.ground_heads)
                {
                    /// --- Program

                    // Note: the head lives in the stage but its index is stored in rule because it is reset each iteration
                    const auto ground_head_rule = make_view(ground_head_index, *rule_stage_execution_context.repository);

                    // Merge it into the program
                    const auto ground_head_index_program = formalism::datalog::merge_d2d(ground_head_rule, merge_context).first;

                    // Insert new fact into fact sets and assigment sets
                    if (!fluent_predicate_fact_sets.contains(ground_head_index_program))
                    {
                        discovered_new_fact = true;

                        const auto ground_head_program = make_view(ground_head_index_program, *program_execution_context.repository);

                        scheduler.on_generate(ground_head_program.get_predicate().get_index());

                        fluent_predicate_fact_sets.insert(ground_head_program);
                        fluent_predicate_assignment_sets.insert(ground_head_program);

                        ++program_execution_context.statistics.num_merges_inserted;
                    }
                    else
                    {
                        ++program_execution_context.statistics.num_merges_discarded;
                    }
                }
            }

            if (!discovered_new_fact)
                break;  ///< Reached fixed point
        }

        scheduler.on_finish_iteration();
    }
}

void solve_bottom_up(datalog::ProgramExecutionContext& program_execution_context)
{
    for (auto& rule_stage_execution_context : program_execution_context.rule_stage_execution_contexts)
        rule_stage_execution_context.clear();

    for (auto& scheduler : program_execution_context.rule_scheduler_strata.data)
    {
        solve_bottom_up_for_stratum(program_execution_context, scheduler);
    }
}
}
